import os
import numpy as np
import yaml
import torch
import logging
logging.basicConfig(level = logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
from model import BertModelForClassification
from transformers_model.models.bert.tokenization_bert import BertTokenizer

from dataset import get_short_text_dataset

from torch.nn.functional import cross_entropy

from torch.optim import AdamW
from torch.utils.data import DataLoader

def train(config):
    train_set, eval_set, test_set = get_short_text_dataset(config)

    logger.info("加载模型...")
    model = BertModelForClassification()

    if config["use_cuda"] and torch.cuda.is_available():
        # model = torch.nn.DataParallel(model)
        model = model.cuda()
        # model = torch.nn.parallel.DistributedDataParallel(model)
    logger.info("加载模型完成...")
    train_dataloader = DataLoader(dataset=train_set, batch_size=config["batch_size"], shuffle=True)
    eval_dataloader = DataLoader(dataset=eval_set, batch_size=config["batch_size"], shuffle=True)
    test_dataloader = DataLoader(dataset=test_set, batch_size=config["batch_size"], shuffle=True)

    optimizer = AdamW(model.parameters(), config["LR"])
    # scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)

    # Train!
    logger.info("***** Running training *****")
    logger.info("  Num train examples = %d", len(train_dataloader) * config["batch_size"])
    logger.info("  Num eval examples = %d", len(eval_dataloader) * config["batch_size"])
    logger.info("  Num test examples = %d", len(test_dataloader) * config["batch_size"])
    logger.info("  Num Epochs = %d", config["EPOCH"])
    logger.info("  Learning rate = %d", config["LR"])

    model.train()

    for epoch in range(config["EPOCH"]):
        for index, batch in enumerate(train_dataloader):
            optimizer.zero_grad()
            input_ids, attention_mask, token_type_ids = \
                batch[0].squeeze(), batch[1].squeeze(), batch[2].squeeze()
            label = batch[3]
            if config["use_cuda"] and torch.cuda.is_available():
                input_ids, attention_mask, token_type_ids = \
                    input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda()
                label = label.cuda()
            model_output = model(input_ids, attention_mask, token_type_ids)

            train_loss = cross_entropy(model_output, label)
            train_loss.backward()
            optimizer.step()

            if index % 10 == 0 and index > 0:
                logger.info("train epoch {}/{} batch {}/{} loss {}".format(str(epoch), str(config["EPOCH"]), str(index),
                                                                           str(len(train_dataloader)),
                                                                           str(train_loss.item())))
            if index % 1000 == 0:
                evaluate(config, model, eval_dataloader)
                if index > 0:
                    checkpoint_name = os.path.join(config["checkpoint_path"],
                                                   "checkpoint-epoch{}-batch{}.bin".format(str(epoch), str(index)))
                    torch.save(model.state_dict(), checkpoint_name)
                    logger.info("saved model!")
            model = model.train()


def evaluate(config, model, eval_dataloader):
    # test
    model = model.eval()
    logger.info("eval!")
    loss_sum = 0
    if config["use_cuda"] and torch.cuda.is_available():
        correct = torch.zeros(1).squeeze().cuda()
        total = torch.zeros(1).squeeze().cuda()
    else:
        correct = torch.zeros(1).squeeze()
        total = torch.zeros(1).squeeze()
    # 创建混淆矩阵
    confuse_matrix = np.zeros((3, 3))

    for index, batch in enumerate(eval_dataloader):
        input_ids, attention_mask, token_type_ids = \
            batch[0].squeeze(), batch[1].squeeze(), batch[2].squeeze()
        label = batch[3]
        if config["use_cuda"] and torch.cuda.is_available():
            input_ids, attention_mask, token_type_ids = \
                input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda()
            label = label.cuda()
        model_output = model(input_ids, attention_mask, token_type_ids)
        eval_loss = cross_entropy(model_output, label)
        loss_sum = loss_sum + eval_loss.item()

        pred = torch.argmax(model_output, dim=1)

        correct += (pred == label).sum().float()
        total += len(label)
        for index in range(len(pred)):
            confuse_matrix[label[index]][pred[index]] = confuse_matrix[label[index]][pred[index]] + 1

    logger.info("eval loss: {}".format(str(loss_sum / (len(eval_dataloader)))))
    logger.info("eval accu: {}".format(str((correct / total).cpu().detach().data.numpy())))
    logger.info("confuse_matrix:")

    logger.info(
        "{}   |   {}   |   {}".format(str(confuse_matrix[0][0]), str(confuse_matrix[0][1]), str(confuse_matrix[0][2])))
    logger.info(
        "{}   |   {}   |   {}".format(str(confuse_matrix[1][0]), str(confuse_matrix[1][1]), str(confuse_matrix[1][2])))
    logger.info(
        "{}   |   {}   |   {}".format(str(confuse_matrix[2][0]), str(confuse_matrix[2][1]), str(confuse_matrix[2][2])))

    logger.info("软件开发 精度 {} 召回率 {}".format(
        str(confuse_matrix[0][0] / (confuse_matrix[0][0] + confuse_matrix[1][0] + confuse_matrix[2][0])),
        str(confuse_matrix[0][0] / (confuse_matrix[0][0] + confuse_matrix[0][1] + confuse_matrix[0][2]))))
    logger.info("会计审计 精度 {} 召回率 {}".format(
        str(confuse_matrix[1][1] / (confuse_matrix[1][1] + confuse_matrix[0][1] + confuse_matrix[2][1])),
        str(confuse_matrix[1][1] / (confuse_matrix[1][1] + confuse_matrix[1][0] + confuse_matrix[1][2]))))
    logger.info("汽车销售 精度 {} 召回率 {}".format(
        str(confuse_matrix[2][2] / (confuse_matrix[2][2] + confuse_matrix[0][2] + confuse_matrix[1][2])),
        str(confuse_matrix[2][2] / (confuse_matrix[2][2] + confuse_matrix[2][0] + confuse_matrix[2][1]))))


if __name__ == '__main__':
    with open(r'config.yaml', 'r', encoding='utf-8') as f:
        result = f.read()
        config = yaml.load(result)
    train(config)